import streamlit as st
import torch
import gdown
import os
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from torchvision.transforms import functional as F
from torchvision.utils import draw_bounding_boxes
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchvision.models.detection import fasterrcnn_resnet50_fpn
import cv2
from torchvision.ops import nms
import json
import io
import base64
import zipfile

# âœ… Google Driveì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜
def download_model(model_name, drive_link):
    model_path = f"models/{model_name}"
    if not os.path.exists(model_path):  # ëª¨ë¸ì´ ì—†ìœ¼ë©´ ë‹¤ìš´ë¡œë“œ
        os.makedirs("models", exist_ok=True)  # í´ë” ìƒì„±
        gdown.download(drive_link, model_path, quiet=False)
    return model_path

# âœ… Google Drive ê³µìœ  ë§í¬ ì„¤ì • (ID ë³€ê²½ í•„ìš”)
model_links = {
    "best_model.pth": "https://drive.google.com/uc?id=11u2cUNul_DZ0bJmykxXr90c9xYQD13CA",
    "best_model_fold_1.pth": "https://drive.google.com/uc?id=1ta9lx56Y74ypc87f-vx7fMlofdCS3O6V",
    "best_model_fold_2.pth": "https://drive.google.com/uc?id=1KzJLz-pMGbUjIVCLBH6WS_ezAsU-nLIi",
    "best_model_fold_3.pth": "https://drive.google.com/uc?id=1eN69P2RvHW7OrdJAHL6qgAML5_ArWXW3",
    "best_model_fold_4.pth": "https://drive.google.com/uc?id=10UNC7LV06GZlqnIvmG9S9F0KUEjLRQfW",
    "best_model_fold_5.pth": "https://drive.google.com/uc?id=11wGXOe6yZZgo8wDmzHrtFiJROn3JusKl",
}

# âœ… í›ˆë ¨ëœ Faster R-CNN ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
@st.cache_resource
def load_model(model_path, num_classes, device):
    model = fasterrcnn_resnet50_fpn(pretrained=True)
    in_features = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)
    model.eval()
    return model

# âœ… ëª¨ë¸ ë° í™˜ê²½ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ
model_path_single = download_model("best_model.pth", model_links["best_model.pth"])  # ë‹¨ì¼ ëª¨ë¸
model_paths_kfold = [
    download_model(f"best_model_fold_{i}.pth", model_links[f"best_model_fold_{i}.pth"])
    for i in range(1, 6)
]  # K-Fold ëª¨ë¸ë“¤

# âœ… í´ë˜ìŠ¤ ì¸ë±ìŠ¤ â†’ ì´ë¦„ ë³€í™˜ ë”•ì…”ë„ˆë¦¬
labels_inv = {1: "extruded", 2: "crack", 3: "cutting", 4: "side_stamped"}

# âœ… Streamlit GUI ì‹œì‘
st.title("ğŸ” O-ring ë¶ˆëŸ‰ í™•ì¸")
st.markdown("### : í›ˆë ¨ëœ Faster R-CNN ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê²°í•¨ íƒì§€")

# âœ… ì™¼ìª½ ì‚¬ì´ë“œë°”ì— ëª¨ë¸ ì„ íƒ ì¶”ê°€
st.sidebar.markdown("<h3 style='font-size:20px;'>ğŸ›  ì‚¬ìš©í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”</h3>", unsafe_allow_html=True)
model_option = st.sidebar.selectbox("", ["ë‹¨ì¼ ëª¨ë¸", "K-Fold ì•™ìƒë¸”"])

# âœ… ì„ íƒí•œ ëª¨ë¸ ë¡œë“œ
if model_option == "ë‹¨ì¼ ëª¨ë¸":
    model = load_model(model_path_single, num_classes=5, device=device)

# âœ… ì™¼ìª½ ì‚¬ì´ë“œë°”ì— ì´ë¯¸ì§€ ì—…ë¡œë“œ ì¶”ê°€
st.sidebar.markdown("<h3 style='font-size:20px;'>ğŸ“‚ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”</h3>", unsafe_allow_html=True)
uploaded_files = st.sidebar.file_uploader("", type=["jpg", "png", "jpeg"], accept_multiple_files=True)

# âœ… ì´ë¯¸ì§€ ì¸ë±ìŠ¤ ì €ì¥ (ì´ì „/ë‹¤ìŒ ë²„íŠ¼ êµ¬í˜„)
if "image_index" not in st.session_state:
    st.session_state.image_index = 0  # ì²« ë²ˆì§¸ ì´ë¯¸ì§€

if uploaded_files:
    num_files = len(uploaded_files)
    
    # âœ… ì—…ë¡œë“œëœ ì´ë¯¸ì§€ê°€ 2ê°œ ì´ìƒì¼ ë•Œë§Œ ìŠ¬ë¼ì´ë” í‘œì‹œ
    if num_files > 1:
        st.markdown("<h3 style='font-size:20px;'>ğŸ“· ì„ íƒëœ ì´ë¯¸ì§€</h3>", unsafe_allow_html=True)
        st.session_state.image_index = st.slider(
            "", 
            min_value=0, max_value=num_files-1, 
            value=st.session_state.image_index
        )
    else:
        st.session_state.image_index = 0  # ì´ë¯¸ì§€ê°€ 1ê°œë¿ì´ë©´ 0ë²ˆì§¸ ì´ë¯¸ì§€ ì„ íƒ
    
    # âœ… í˜„ì¬ ì´ë¯¸ì§€ ì„ íƒ
    uploaded_file = uploaded_files[st.session_state.image_index]

    # âœ… ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
    image = Image.open(uploaded_file).convert("RGB")
    
    # âœ… OpenCVë¡œ ë³€í™˜ í›„ ì „ì²˜ë¦¬ (ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜ ë° ROI ì„ íƒ)
    img_cv = np.array(image)
    gray = cv2.cvtColor(img_cv, cv2.COLOR_RGB2GRAY)
    _, binary = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY_INV)
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # âœ… ê°€ì¥ í° ê°ì²´ ì˜ì—­ ì„ íƒ
    if contours:
        contour = max(contours, key=cv2.contourArea)
        x, y, w, h = cv2.boundingRect(contour)
        margin = 20
        height, width, _ = img_cv.shape
        x_new, y_new = max(0, x - margin), max(0, y - margin)
        x_end, y_end = min(width, x + w + margin), min(height, y + h + margin)
        cropped = img_cv[y_new:y_end, x_new:x_end]
        resized_image = cv2.resize(cropped, (500, 500), interpolation=cv2.INTER_LINEAR)
        image = Image.fromarray(resized_image)

    # âœ… ì´ë¯¸ì§€ í…ì„œ ë³€í™˜
    img_tensor = F.to_tensor(image).to(device)

    # âœ… ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰
    if model_option == "ë‹¨ì¼ ëª¨ë¸":  # ë‹¨ì¼ ëª¨ë¸ ì‚¬ìš©
        with torch.no_grad():
            pred = model([img_tensor])[0]
            # âœ… ë°”ìš´ë”© ë°•ìŠ¤, ì ìˆ˜, ë¼ë²¨ ì¶”ì¶œ
        boxes = pred["boxes"]
        scores = pred["scores"]
        labels = pred["labels"]

        # âœ… ì‹ ë¢°ë„ ì„ê³„ê°’(0.5) ì ìš©
        threshold = 0.5
        keep = scores > threshold
        final_boxes = boxes[keep]
        final_scores = scores[keep]
        final_labels = labels[keep]

    else:  # âœ… K-Fold ëª¨ë¸ Lazy Loading ì ìš© (í•œ ë²ˆì— ë¡œë“œ X, í•˜ë‚˜ì”© ë¶ˆëŸ¬ì˜¤ê¸°)
        final_boxes_list, final_scores_list, final_labels_list = [], [], []
        
        for path in model_paths_kfold:
            model_kfold = load_model(path, num_classes=5, device=device)  # í•˜ë‚˜ì”© ë¡œë“œ
            with torch.no_grad():
                pred = model_kfold([img_tensor])[0]
            final_boxes_list.append(pred["boxes"])
            final_scores_list.append(pred["scores"])
            final_labels_list.append(pred["labels"])

        # âœ… ê²°ê³¼ ë³‘í•©
        final_boxes = torch.cat(final_boxes_list, dim=0)
        final_scores = torch.cat(final_scores_list, dim=0)
        final_labels = torch.cat(final_labels_list, dim=0)

        # âœ… NMS ì ìš©
        iou_threshold, score_threshold = 0.3, 0.5
        keep = final_scores > score_threshold
        final_boxes, final_scores, final_labels = final_boxes[keep], final_scores[keep], final_labels[keep]
        keep_indices = nms(final_boxes, final_scores, iou_threshold)
        final_boxes, final_scores, final_labels = final_boxes[keep_indices], final_scores[keep_indices], final_labels[keep_indices]

    # âœ… ì´ì „/ë‹¤ìŒ ë²„íŠ¼ UI (ë¹„í™œì„±í™” ì¶”ê°€)
    col1, col2, col3 = st.columns([1, 6, 1])

    with col1:
        st.button("â¬… ì´ì „", key="prev", disabled=(st.session_state.image_index == 0), 
                  on_click=lambda: st.session_state.update({"image_index": st.session_state.image_index - 1}))

    with col3:
        st.button("ë‹¤ìŒ â¡", key="next", disabled=(st.session_state.image_index == num_files - 1), 
                  on_click=lambda: st.session_state.update({"image_index": st.session_state.image_index + 1}))
                
    # âœ… ë°”ìš´ë”© ë°•ìŠ¤ê°€ ìˆëŠ”ì§€ ì—¬ë¶€ í™•ì¸ í›„ ìƒ‰ìƒ ì„¤ì •
    if len(final_boxes) > 0:
        result_text = "âš  ê²°í•¨ ì¡´ì¬!"
        text_color = "red"
    else:
        result_text = "âœ… ê²°í•¨ ì—†ìŒ!"
        text_color = "black"

    # âœ… ê²°í•¨ ì—¬ë¶€ í…ìŠ¤íŠ¸ ì¶œë ¥ (ê°€ìš´ë° ì •ë ¬ + ìƒ‰ìƒ ë³€ê²½)
    st.markdown(
        f"<h2 style='text-align: center; color: {text_color};'>{result_text}</h2>",
        unsafe_allow_html=True
    )

    # âœ… ë°”ìš´ë”© ë°•ìŠ¤ ì‹œê°í™”
    img_with_boxes = draw_bounding_boxes(
        (img_tensor * 255).byte(), final_boxes, colors="red", width=3
    )

    # âœ… Matplotlibì„ ì‚¬ìš©í•˜ì—¬ ì‹œê°í™”
    fig, ax = plt.subplots(figsize=(8, 8))
    ax.imshow(img_with_boxes.permute(1, 2, 0).cpu())

    for i in range(len(final_boxes)):
        x1, y1, _, _ = final_boxes[i]
        label = labels_inv.get(final_labels[i].item(), "Unknown")
        score = final_scores[i].item()
        ax.text(x1.item(), y1.item() - 5, f"{label} ({score:.2f})",
                color='white', fontsize=15, weight='bold', bbox=dict(facecolor='red', alpha=0.5))

    ax.axis("off")
    st.pyplot(fig)

# âœ… ê²°ê³¼ ì´ë¯¸ì§€ì™€ JSON ë°ì´í„° ì €ì¥ì„ ìœ„í•œ ë¦¬ìŠ¤íŠ¸
all_results = []
all_images = []

# âœ… ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜ (ZIPìœ¼ë¡œ ì €ì¥)
def get_zip_download_link(zip_filename="results.zip"):
    """ì—¬ëŸ¬ ê°œì˜ ê²°ê³¼ íŒŒì¼ì„ ZIPìœ¼ë¡œ ë¬¶ì–´ ë‹¤ìš´ë¡œë“œ"""
    zip_buffer = io.BytesIO()

    with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zipf:
        for img_name, img_pil in all_images:
            img_io = io.BytesIO()
            img_pil.save(img_io, format="JPEG")
            zipf.writestr(f"images/{img_name}", img_io.getvalue())

        # JSON ì €ì¥
        json_str = json.dumps(all_results, indent=4)
        zipf.writestr("results.json", json_str)

    zip_buffer.seek(0)
    b64 = base64.b64encode(zip_buffer.getvalue()).decode()
    href = f'<a href="data:application/zip;base64,{b64}" download="{zip_filename}">ğŸ“¥ ê²°ê³¼ ZIP ë‹¤ìš´ë¡œë“œ</a>'
    return href

# âœ… ëª¨ë“  ì´ë¯¸ì§€ ì €ì¥ ë²„íŠ¼ UI
if st.button("ğŸ’¾ ì „ì²´ ê²°ê³¼ ì €ì¥"):
    all_results.clear()
    all_images.clear()

    for idx, uploaded_file in enumerate(uploaded_files):
        # âœ… ì´ë¯¸ì§€ ë¡œë“œ
        image_name = uploaded_file.name  # ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„
        image = Image.open(uploaded_file).convert("RGB")

        # âœ… ì´ë¯¸ì§€ ì²˜ë¦¬ (ë°”ìš´ë”© ë°•ìŠ¤ ì¶”ê°€)
        img_with_boxes = draw_bounding_boxes(
            (F.to_tensor(image) * 255).byte(), final_boxes, colors="red", width=3
        )

        img_pil = Image.fromarray(img_with_boxes.permute(1, 2, 0).byte().cpu().numpy())

        # âœ… JSON ë°ì´í„° ì €ì¥
        result_data = {
            "image_name": image_name,
            "num_detections": len(final_boxes),
            "detections": []
        }

        for i in range(len(final_boxes)):
            x1, y1, x2, y2 = final_boxes[i].tolist()
            label = labels_inv.get(final_labels[i].item(), "Unknown")
            score = round(final_scores[i].item(), 2)
            
            result_data["detections"].append({
                "label": label,
                "confidence": score,
                "bbox": [x1, y1, x2, y2]
            })

        all_results.append(result_data)
        all_images.append((image_name, img_pil))

    # âœ… ZIP ë‹¤ìš´ë¡œë“œ ë§í¬ ìƒì„±
    st.markdown(get_zip_download_link(), unsafe_allow_html=True)
